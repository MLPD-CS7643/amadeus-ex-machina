{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T01:00:59.770861Z",
     "start_time": "2024-12-06T01:00:54.758059Z"
    }
   },
   "outputs": [],
   "source": [
    "# System imports\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of 'notebooks' to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Move one level up\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Class/model imports\n",
    "from data.data_loader import MirDataProcessor\n",
    "from utils.model_utils import get_device, run_tabular_chroma_inference\n",
    "from solver import Solver\n",
    "import data.youtube_download as youtube_download\n",
    "\n",
    "# Package imports\n",
    "import torch\n",
    "\n",
    "# Select device\n",
    "device = get_device()\n",
    "print(f\"Device is {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download and build useable train/test data out of the MIR Billboard dataset\n",
    "# data_processer = MirDataProcessor(download=True, batch_size=64)\n",
    "# data_processer.process_billboard_data()\n",
    "\n",
    "# # Create data loeaders for train and test set\n",
    "# train_loader, test_loader, num_classes = data_processer.build_data_loaders()\n",
    "\n",
    "# print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set billboard data path\n",
    "billboard_data_path = \"../data/raw/McGill-Billboard\"\n",
    "output_path = \"../data/processed/McGill-Billboard\"\n",
    "\n",
    "# Download through salami_chord file processing\n",
    "# youtube_download.process_lab_files(billboard_data_path, 0, 200)\n",
    "\n",
    "# Process the downloaded data\n",
    "youtube_download.process_downloaded_songs(billboard_data_path, output_path, threshold=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize Solver for MLPChordClassifier\n",
    "# mlp_chord_classifier_solver = Solver(\n",
    "#     model_type=\"MLPChordClassifier\",\n",
    "#     model_kwargs={\"input_size\": 24, \"num_classes\": num_classes},\n",
    "#     device=device,\n",
    "#     batch_size=128,\n",
    "#     learning_rate=0.001,\n",
    "#     epochs=20,\n",
    "# )\n",
    "\n",
    "# # Train and evaluate the model\n",
    "# mlp_chord_classifier_solver.train_and_evaluate(train_loader, test_loader, plot_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize Solver for CRNNModel\n",
    "# crnn_model_solver = Solver(\n",
    "#     model_type=\"CRNNModel\",\n",
    "#     model_kwargs={\"input_features\": 24, \"num_classes\": num_classes, \"hidden_size\": 128},\n",
    "#     device=device,\n",
    "#     batch_size=128,\n",
    "#     learning_rate=0.001,\n",
    "#     epochs=20,\n",
    "# )\n",
    "\n",
    "# crnn_model_solver.train_and_evaluate(train_loader, test_loader, plot_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize Solver for CNNModel\n",
    "# cnn_model_solver = Solver(\n",
    "#     model_type=\"CNNModel\",\n",
    "#     model_kwargs={\"input_channels\": 24, \"num_classes\": num_classes},\n",
    "#     device=device,\n",
    "#     batch_size=128,\n",
    "#     learning_rate=0.001,\n",
    "#     epochs=20,\n",
    "# )\n",
    "\n",
    "# cnn_model_solver.train_and_evaluate(train_loader, test_loader, plot_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize Solver for RNNModel\n",
    "# rnn_model_solver = Solver(\n",
    "#     model_type=\"RNNModel\",\n",
    "#     model_kwargs={\"input_size\": 24, \"hidden_size\": 128, \"output_size\": num_classes},\n",
    "#     device=device,\n",
    "#     batch_size=128,\n",
    "#     learning_rate=0.001,\n",
    "#     epochs=20,\n",
    "# )\n",
    "\n",
    "# rnn_model_solver.train_and_evaluate(train_loader, test_loader, plot_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = data_processor.scaler\n",
    "# label_encoder = data_processor.label_encoder\n",
    "# chroma_path = \"/my/path/to/amadeus-ex-machina/data/raw/McGill-Billboard/0003/bothchroma.csv\"\n",
    "\n",
    "# # Run inference using the trained model\n",
    "# solver.run_inference(\n",
    "#     chroma_path,\n",
    "#     scaler,\n",
    "#     label_encoder,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amadeus-ex-machina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
