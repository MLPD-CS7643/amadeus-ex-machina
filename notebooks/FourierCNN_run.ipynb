{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mattb\\miniconda3\\envs\\amadeus-ex-machina\\Lib\\site-packages\\tqdm_joblib\\__init__.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# System imports\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of 'notebooks' to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Move one level up\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Class/model imports\n",
    "from data.data_loader import MirDataProcessor\n",
    "from utils.model_utils import get_device\n",
    "from solver import Solver\n",
    "\n",
    "# Package imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Select device\n",
    "device = get_device()\n",
    "print(f\"Device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Zip and tar files will be deleted after they are uncompressed. If you download this dataset again, it will overwrite existing files, even if force_overwrite=False\n",
      "INFO: Downloading ['annotations', 'audio_hex_debleeded', 'audio_hex_original', 'audio_mic', 'audio_mix', 'index']. Index is being stored in C:\\Users\\mattb\\miniconda3\\envs\\amadeus-ex-machina\\Lib\\site-packages\\mirdata\\datasets\\indexes, and the rest of files in c:\\Users\\mattb\\Documents\\CS7643\\Final Project\\amadeus-ex-machina\\data\\raw\n",
      "INFO: [annotations] downloading annotation.zip\n",
      "37.3MB [00:02, 14.5MB/s]                              \n",
      "INFO: [audio_hex_debleeded] downloading audio_hex-pickup_debleeded.zip\n",
      "3.36GB [02:29, 24.1MB/s]                               \n",
      "INFO: [audio_hex_original] downloading audio_hex-pickup_original.zip\n",
      "2.99GB [01:57, 27.2MB/s]                               \n",
      "INFO: [audio_mic] downloading audio_mono-mic.zip\n",
      "626MB [00:25, 25.8MB/s]                               \n",
      "INFO: [audio_mix] downloading audio_mono-pickup_mix.zip\n",
      "652MB [00:33, 20.4MB/s]                               \n",
      "INFO: [index] downloading guitarset_index_1.1.0.json\n",
      "248kB [00:00, 372kB/s]                             \n"
     ]
    }
   ],
   "source": [
    "# Download and build useable train/test data out of the MIR Billboard dataset\n",
    "data_processer = MirDataProcessor(download=True, batch_size=64, dataset_name=\"guitarset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Found 360 tracks in the dataset.\n",
      "Processing dataset as sequential data\n",
      "Processed track 00_BN1-129-Eb_comp and appended data to combined CSV.\n",
      "Processing dataset as sequential data\n",
      "Processed track 00_BN1-129-Eb_solo and appended data to combined CSV.\n",
      "All data processed and saved to c:\\Users\\mattb\\Documents\\CS7643\\Final Project\\amadeus-ex-machina\\data\\processed\\combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from data.data_loader import MirDataProcessor\n",
    "data_processer = MirDataProcessor(download=False, batch_size=64, dataset_name=\"guitarset\", process_sequential=True, seq_length=4096)\n",
    "\n",
    "data_processer.process_wav_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model data...\n",
      "Loading the combined CSV file...\n",
      "Separating song IDs, features, and labels...\n",
      "Scaling features using MinMaxScaler...\n",
      "Encoding labels using LabelEncoder...\n",
      "Saving the scaler to c:\\Users\\mattb\\Documents\\CS7643\\Final Project\\amadeus-ex-machina\\data\\processed\\scaler.pkl...\n",
      "Saving the label encoder to c:\\Users\\mattb\\Documents\\CS7643\\Final Project\\amadeus-ex-machina\\data\\processed\\label_encoder.pkl...\n",
      "Creating sequences of chromagram data within song boundaries...\n",
      "Splitting data into training and testing sets...\n",
      "Data preparation complete.\n",
      "Number of classes determined: 3\n",
      "Creating TensorDatasets for training and testing data...\n",
      "Creating DataLoaders for training and testing datasets...\n",
      "Data loaders are ready for training and testing.\n",
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "# Create data loeaders for train and test set\n",
    "train_loader, test_loader, num_classes = data_processer.build_data_loaders(None, device)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Epoch 1\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fbdb0f168940c290f2bffed86d7a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0239. Validation Loss: 0.8772.\n",
      "Training Accuracy: 0.4245. Validation Accuracy: 0.6740.\n",
      "-----------------------------------\n",
      "Epoch 2\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8acdb7c4cc4e589f1d07dc713d8a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8361. Validation Loss: 0.8165.\n",
      "Training Accuracy: 0.6647. Validation Accuracy: 0.6740.\n",
      "-----------------------------------\n",
      "Epoch 3\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdce83f584f4b44b31cae383be23b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8285. Validation Loss: 0.8151.\n",
      "Training Accuracy: 0.6647. Validation Accuracy: 0.6740.\n",
      "-----------------------------------\n",
      "Epoch 4\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340d029138054248b607ea9e89635d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8277. Validation Loss: 0.8151.\n",
      "Training Accuracy: 0.6647. Validation Accuracy: 0.6740.\n",
      "-----------------------------------\n",
      "Epoch 5\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70354e923f14109b1a36e1622e7047a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8280. Validation Loss: 0.8170.\n",
      "Training Accuracy: 0.6647. Validation Accuracy: 0.6740.\n",
      "-----------------------------------\n",
      "Epoch 6\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4eeb6658e448b99f9ddca5ecafb529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8277. Validation Loss: 0.8144.\n",
      "Training Accuracy: 0.6647. Validation Accuracy: 0.6740.\n",
      "-----------------------------------\n",
      "Epoch 7\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9f777be3f54f90b4b7a37ca0ee0cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8278. Validation Loss: 0.8132.\n",
      "Training Accuracy: 0.6647. Validation Accuracy: 0.6740.\n",
      "-----------------------------------\n",
      "Epoch 8\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b04df09bc5f4f3e93249f574fa683b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8266. Validation Loss: 0.8177.\n",
      "Training Accuracy: 0.6647. Validation Accuracy: 0.6740.\n",
      "-----------------------------------\n",
      "Epoch 9\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bfa038f70e43f09ea91075e14ae247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8261. Validation Loss: 0.8133.\n",
      "Training Accuracy: 0.6647. Validation Accuracy: 0.6740.\n",
      "-----------------------------------\n",
      "Epoch 10\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e7b3ea32414b3bbef87ed87c845ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.FourierS2S import FourierS2S\n",
    "\n",
    "model = FourierS2S(1024, 1024, 1024, 128, 128, num_classes, 4096, device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\n",
    "\n",
    "\n",
    "# Initialize Solver for CRNNModel\n",
    "fourierS2S_solver = Solver(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    train_dataloader=train_loader,\n",
    "    valid_dataloader=test_loader,\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    device=device,\n",
    "    early_stop_epochs=3,\n",
    "    warmup_epochs=2,\n",
    "    optuna_prune=False\n",
    ")\n",
    "fourierS2S_solver.train_and_evaluate(plot_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amadeus-ex-machina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
