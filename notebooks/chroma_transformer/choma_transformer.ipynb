{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# System imports\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of 'notebooks' to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # Move one level up\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from solver import Solver\n",
    "from griddy.griddy_tuna import hit_griddy, SearchMethod\n",
    "from models.ChromaTransformer import ChromaTransformerModel\n",
    "from data.data_loader import MirDataProcessor\n",
    "from utils.model_utils import get_device\n",
    "from solver import TrialMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "print(f\"Device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model data...\n",
      "Loading the combined CSV file...\n",
      "Separating song IDs, features, and labels...\n",
      "Scaling features using MinMaxScaler...\n",
      "Encoding labels using LabelEncoder...\n",
      "Saving the scaler to c:\\Users\\maxwe\\OneDrive\\Documents\\amadeus-ex-machina\\data\\processed\\scaler.pkl...\n",
      "Saving the label encoder to c:\\Users\\maxwe\\OneDrive\\Documents\\amadeus-ex-machina\\data\\processed\\label_encoder.pkl...\n",
      "Creating sequences of chromagram data within song boundaries...\n",
      "Splitting data into training and testing sets...\n",
      "Data preparation complete.\n",
      "Number of classes determined: 976\n",
      "Creating TensorDatasets for training and testing data...\n",
      "Creating DataLoaders for training and testing datasets...\n",
      "Data loaders are ready for training and testing.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the data processor and create data loaders\n",
    "data_processor = MirDataProcessor(batch_size=256, process_sequential=True, seq_length=16, overlap_sequence=True, use_median=True)\n",
    "train_loader, test_loader, num_classes = data_processor.build_data_loaders(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Do not assume these values are anything but trash, they're just here for testing\n",
    "\n",
    "SOLVER_PARAMS = {\n",
    "    Solver : {\n",
    "        \"device\": device,\n",
    "        \"batch_size\": 256,\n",
    "        \"epochs\": [5, 10],\n",
    "        \"early_stop_epochs\": 3, # early stop after n epochs without improvement, 0 to disable\n",
    "        \"warmup_epochs\": 0, # 0 to disable\n",
    "        \"dtype\": \"float16\",\n",
    "        \"train_dataloader\": train_loader, # must be DataLoader object\n",
    "        \"valid_dataloader\": test_loader, # must be DataLoader object\n",
    "        \"direction\": \"minimize\" # must specify this, even if not used by solver\n",
    "    }\n",
    "}\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "    ChromaTransformerModel: {\n",
    "        \"input_dim\": [24],\n",
    "        \"seq_length\": [16],\n",
    "        \"num_classes\": [num_classes],\n",
    "        \"dim_feedworward\": [256, 512, 1024],\n",
    "        \"d_model\": [128, 256],\n",
    "        \"num_layers\": [4, 6]\n",
    "    }\n",
    "}\n",
    "\n",
    "OPTIM_PARAMS = {\n",
    "    torch.optim.SGD : {\n",
    "        \"lr\": [0.001, 0.1, SearchMethod.LOG_UNIFORM],\n",
    "        \"momentum\": [0.9, 0.99, SearchMethod.UNIFORM],\n",
    "        \"weight_decay\": [0.00001],\n",
    "    },\n",
    "    torch.optim.Adam : {\n",
    "        \"lr\": [0.008, 0.005, 0.001], # this will auto-search as CATEGORICAL\n",
    "    }\n",
    "}\n",
    "\n",
    "SCHED_PARAMS = {\n",
    "    torch.optim.lr_scheduler.CosineAnnealingWarmRestarts : {\n",
    "        \"T_0\": [10],\n",
    "    },\n",
    "    torch.optim.lr_scheduler.StepLR : {\n",
    "        \"step_size\": [5, 10, 15],\n",
    "        \"gamma\" : [0.1, 0.05],\n",
    "    }\n",
    "}\n",
    "\n",
    "CRITERION_PARAMS = {\n",
    "    torch.nn.CrossEntropyLoss : {}\n",
    "}\n",
    "\n",
    "PARAM_SET = {\n",
    "    \"solver\": SOLVER_PARAMS,\n",
    "    \"model\" : MODEL_PARAMS,\n",
    "    \"optim\" : OPTIM_PARAMS,\n",
    "    \"sched\" : SCHED_PARAMS,\n",
    "    \"criterion\" : CRITERION_PARAMS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Hitting the griddy...\" -Ellie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 17:46:29,229] A new study created in RDB with name: chroma_transformer\n",
      "c:\\Users\\maxwe\\OneDrive\\Documents\\amadeus-ex-machina\\griddy\\griddy_tuna.py:127: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  return trial.suggest_loguniform(name, min(values), max(values))\n",
      "c:\\Users\\maxwe\\OneDrive\\Documents\\amadeus-ex-machina\\griddy\\griddy_tuna.py:125: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  return trial.suggest_uniform(name, min(values), max(values))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Epoch 1\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043aacab14514f208d62c0fc561578f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/12893 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.8452. Validation Loss: 1.4233.\n",
      "Training Accuracy: 0.5426. Validation Accuracy: 0.6201.\n",
      "-----------------------------------\n",
      "Epoch 2\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxwe\\anaconda3\\envs\\amadeus-ex-machina\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7c25ace8314c6d9bd13713900a7e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/12893 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_study = \"chroma_transformer\"\n",
    "\n",
    "output_folder = Path(\"griddy\")\n",
    "\n",
    "solver_reference = hit_griddy(my_study, param_set=PARAM_SET, out_dir=output_folder, n_trials=30, n_jobs=1, prune=False, resume=False, trial_metric=TrialMetric.ACCURACY)\n",
    "# NOTE: modest values of n_trials and n_jobs set here for testing, set your values accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amadeus-ex-machina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
