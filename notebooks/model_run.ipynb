{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or update conda environment\n",
    "# !conda env create -f ../environment.yaml\n",
    "# !conda env update -f ../environment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate conda environment\n",
    "!conda activate amadeus-ex-machina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent directory added to sys.path: c:\\Users\\mattb\\Documents\\CS7643\\Final Project\n"
     ]
    }
   ],
   "source": [
    "# System imports\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of 'notebooks' to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Move one level up\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Test if the path is correctly added\n",
    "print(f\"Parent directory added to sys.path: {parent_dir}\")\n",
    "\n",
    "# Import packages\n",
    "import json\n",
    "import torchaudio\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Import models\n",
    "from models.CRNN import CRNNModel\n",
    "from models.CNN import CNNModel\n",
    "from models.RNN import RNNModel\n",
    "from models.AudioDataset import ChordDataset\n",
    "from models.FourierCNN import FourierCNN\n",
    "\n",
    "# Import utils\n",
    "from datagen.chordgen import generate_all_chords\n",
    "\n",
    "json_file = \"../datagen/chords/chord_ref.json\"\n",
    "audio_dir = \"../datagen/chords/midi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datagen/chords/chord_ref.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Data preprocessing\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the JSON metadata\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Create a mapping for chord classes to integers\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mattb\\miniconda3\\envs\\amadeus-ex-machina\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datagen/chords/chord_ref.json'"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "# Load the JSON metadata\n",
    "with open(json_file, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Create a mapping for chord classes to integers\n",
    "chord_classes = sorted({value[\"chord_class\"] for value in metadata.values()})\n",
    "chord_class_to_idx = {chord: idx for idx, chord in enumerate(chord_classes)}\n",
    "print(\"Chord Class to Index Mapping:\", chord_class_to_idx)\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "dataset = ChordDataset(metadata, audio_dir, chord_class_to_idx)\n",
    "\n",
    "# Split into training and validation datasets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Move model to the selected device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Get the number of classes\n",
    "num_classes = len(chord_class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modular training and validation function\n",
    "\n",
    "def training_validation(model):\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training Loop\n",
    "    num_epochs = 20\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Loop over the batches in the training dataset\n",
    "        for spectrograms, labels in train_loader:\n",
    "            # Move data to the selected device\n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "            # Zero gradients from the previous step\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(spectrograms)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update model weights\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Print training loss for the current epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        # Evaluate on validation data after every epoch\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():  # No need to compute gradients during evaluation\n",
    "            for spectrograms, labels in val_loader:\n",
    "                spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "                outputs = model(spectrograms)\n",
    "                _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f\"Validation Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.0522\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [2/20], Loss: 0.7225\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [3/20], Loss: 0.6021\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [4/20], Loss: 0.5103\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [5/20], Loss: 0.4194\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [6/20], Loss: 0.2809\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [7/20], Loss: 0.1616\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [8/20], Loss: 0.1042\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [9/20], Loss: 0.0653\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [10/20], Loss: 0.0400\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [11/20], Loss: 0.0294\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [12/20], Loss: 0.0256\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [13/20], Loss: 0.0171\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [14/20], Loss: 0.0107\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [15/20], Loss: 0.0081\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [16/20], Loss: 0.0064\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [17/20], Loss: 0.0051\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [18/20], Loss: 0.0041\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [19/20], Loss: 0.0033\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [20/20], Loss: 0.0029\n",
      "Validation Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Initialize CRNN model\n",
    "crnn_model = CRNNModel(input_channels=2, num_classes=num_classes, hidden_size=128).to(device)\n",
    "training_validation(crnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.0743\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [2/20], Loss: 0.9833\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [3/20], Loss: 0.9092\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [4/20], Loss: 0.8458\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [5/20], Loss: 0.7982\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [6/20], Loss: 0.7609\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [7/20], Loss: 0.7320\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [8/20], Loss: 0.7081\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [9/20], Loss: 0.6881\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [10/20], Loss: 0.6718\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [11/20], Loss: 0.6566\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [12/20], Loss: 0.6426\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [13/20], Loss: 0.6313\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [14/20], Loss: 0.6193\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [15/20], Loss: 0.6078\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [16/20], Loss: 0.5967\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [17/20], Loss: 0.5864\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [18/20], Loss: 0.5760\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [19/20], Loss: 0.5656\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [20/20], Loss: 0.5554\n",
      "Validation Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Initialize CNN model\n",
    "cnn_model = CNNModel(input_channels=2, num_classes=num_classes).to(device)\n",
    "training_validation(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.3357\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [2/20], Loss: 0.1893\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [3/20], Loss: 0.0373\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [4/20], Loss: 0.0818\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [5/20], Loss: 0.0679\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [6/20], Loss: 0.0008\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [7/20], Loss: 0.0000\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [8/20], Loss: 0.0001\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [9/20], Loss: 0.0002\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [10/20], Loss: 0.0004\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [11/20], Loss: 0.0007\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [12/20], Loss: 0.0011\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [13/20], Loss: 0.0014\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [14/20], Loss: 0.0015\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [15/20], Loss: 0.0012\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [16/20], Loss: 0.0009\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [17/20], Loss: 0.0006\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [18/20], Loss: 0.0004\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [19/20], Loss: 0.0002\n",
      "Validation Accuracy: 0.00%\n",
      "Epoch [20/20], Loss: 0.0001\n",
      "Validation Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the flattened size of the spectrograms\n",
    "for spectrograms, _ in train_loader:\n",
    "    rnn_input_size = spectrograms.view(spectrograms.size(0), -1).size(1)\n",
    "    break\n",
    "\n",
    "# Initialize the RNN model\n",
    "rnn_model = RNNModel(input_size=rnn_input_size, hidden_size=128, output_size=num_classes).to(device)\n",
    "training_validation(rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the FourierCNN model\n",
    "#TODO Calculate input and output size\n",
    "input_size = None\n",
    "output_size = None\n",
    "fouriercnn_model = FourierCNN(input_size, 128, 128, 128, output_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amadeus-ex-machina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
